{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from utils import TrainingPlot, TimeSummary, plot_training_summary\n",
    "from NNKeras import NNKeras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Data Cleanup\n",
    "-  Merge 64 size vectors by ignoring line breaks\n",
    "-  Create subset of data by selecting non consecutive vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaned data\n",
    "L42023,0.04347826,0.04347826,0.,0.04347826,0.01086957,0.02173913,0.,0.02173913,0.,0.,0.,0.,0.,0.02173913,0.02173913,0.04347826,0.07608696,0.02173913,0.,0.0326087,0.01086957,0.,0.,0.0326087,0.,0.01086957,0.,0.0326087,0.,0.,0.,0.0326087,0.05434783,0.,0.01086957,0.02173913,0.04347826,0.,0.01086957,0.02173913,0.02173913,0.,0.,0.01086957,0.0326087,0.,0.04347826,0.0326087,0.01086957,0.01086957,0.,0.02173913,0.04347826,0.01086957,0.,0.01086957,0.,0.,0.,0.,0.04347826,0.02173913,0.,0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "## Network 1\n",
    "### Create input dataset X and y where X has all vectors and y is one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NNKeras(\"/tf/dataset/dataset.csv\")\n",
    "X, y, unique_classes = nn.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131, 64)\n",
      "(3131, 31)\n",
      "         1         2         3         4         5         6         7   \\\n",
      "0  0.045455  0.045455  0.000000  0.000000  0.045455  0.318182  0.000000   \n",
      "1  0.080000  0.060000  0.000000  0.100000  0.000000  0.000000  0.020000   \n",
      "2  0.010482  0.020964  0.002096  0.012579  0.004193  0.031447  0.006289   \n",
      "\n",
      "         8    9         10  ...        55        56        57        58  \\\n",
      "0  0.000000  0.0  0.045455  ...  0.000000  0.000000  0.045455  0.000000   \n",
      "1  0.000000  0.0  0.000000  ...  0.000000  0.020000  0.020000  0.040000   \n",
      "2  0.006289  0.0  0.014675  ...  0.010482  0.006289  0.000000  0.010482   \n",
      "\n",
      "        59        60        61        62        63        64  \n",
      "0  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1  0.00000  0.000000  0.020000  0.000000  0.000000  0.000000  \n",
      "2  0.02935  0.008386  0.010482  0.020964  0.012579  0.054507  \n",
      "\n",
      "[3 rows x 64 columns]\n",
      "[[ True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False]\n",
      " [ True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False]\n",
      " [ True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X[:3])\n",
    "print(y[:3])\n",
    "unique_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Randomly select train, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1         2         3         4         5         6         7   \\\n",
      "2113  0.000000  0.013333  0.005333  0.000000  0.000000  0.026667  0.013333   \n",
      "3029  0.075269  0.043011  0.043011  0.021505  0.000000  0.010753  0.000000   \n",
      "2130  0.056338  0.004695  0.000000  0.046948  0.014085  0.000000  0.004695   \n",
      "\n",
      "            8         9         10  ...        55        56        57     58  \\\n",
      "2113  0.000000  0.000000  0.008000  ...  0.018667  0.002667  0.002667  0.008   \n",
      "3029  0.000000  0.021505  0.000000  ...  0.010753  0.000000  0.000000  0.000   \n",
      "2130  0.023474  0.009390  0.004695  ...  0.004695  0.014085  0.000000  0.000   \n",
      "\n",
      "            59       60        61        62        63        64  \n",
      "2113  0.016000  0.00000  0.000000  0.029333  0.002667  0.000000  \n",
      "3029  0.010753  0.00000  0.021505  0.010753  0.010753  0.010753  \n",
      "2130  0.009390  0.00939  0.042254  0.004695  0.037559  0.028169  \n",
      "\n",
      "[3 rows x 64 columns]\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False  True False False False\n",
      "  False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False  True False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False  True False False\n",
      "  False False False False False False False]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "print(X_train[:3])\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['    def train(self, X, y, node_range, show_summary: bool = False):\\n',\n",
       "  '        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=5)\\n',\n",
       "  '        for num_nodes in node_range:\\n',\n",
       "  '            nodes = [64, num_nodes]\\n',\n",
       "  '            model = self.base_model(nodes)\\n',\n",
       "  '            summary = model.fit(X_train, y_train, epochs=10, verbose=0)\\n',\n",
       "  '            score = model.evaluate(X_test, y_test)\\n',\n",
       "  '            if show_summary:\\n',\n",
       "  '                model.summary()\\n',\n",
       "  \"            print('Test loss:', score[0])\\n\",\n",
       "  \"            print('Test accuracy:', score[1])\\n\"],\n",
       " 53)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsourcelines(nn.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 31)                62        \n",
      "=================================================================\n",
      "Total params: 127\n",
      "Trainable params: 127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.15585796535015106\n",
      "Test accuracy: 0.9677419066429138\n"
     ]
    }
   ],
   "source": [
    "nn.train(X, y, range(1, 2), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 2\n",
    "### Use the training method for nodes 5 - 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "Test loss: 0.1429307907819748\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Test loss: 0.14281298220157623\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Test loss: 0.14325407147407532\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Test loss: 0.1425652951002121\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Test loss: 0.14129656553268433\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Test loss: 0.1418779492378235\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 12ms/step\n",
      "Test loss: 0.1425275206565857\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 11ms/step\n",
      "Test loss: 0.1427726298570633\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Test loss: 0.14244911074638367\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 11ms/step\n",
      "Test loss: 0.1420992910861969\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 23ms/step\n",
      "Test loss: 0.14269563555717468\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 16ms/step\n",
      "Test loss: 0.14084286987781525\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 11ms/step\n",
      "Test loss: 0.1416197121143341\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 19ms/step\n",
      "Test loss: 0.14277976751327515\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 20ms/step\n",
      "Test loss: 0.14155976474285126\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 27ms/step\n",
      "Test loss: 0.14243900775909424\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 20ms/step\n",
      "Test loss: 0.14054928719997406\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 13ms/step\n",
      "Test loss: 0.1378220021724701\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 0s 14ms/step\n",
      "Test loss: 0.13677063584327698\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 24ms/step\n",
      "Test loss: 0.1416948139667511\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 25ms/step\n",
      "Test loss: 0.13580386340618134\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 19ms/step\n",
      "Test loss: 0.138200581073761\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 16ms/step\n",
      "Test loss: 0.1381121128797531\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 29ms/step\n",
      "Test loss: 0.13999968767166138\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 18ms/step\n",
      "Test loss: 0.13512934744358063\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 31ms/step\n",
      "Test loss: 0.14227181673049927\n",
      "Test accuracy: 0.9677419066429138\n",
      "32/32 [==============================] - 1s 34ms/step\n",
      "Test loss: 0.13853079080581665\n",
      "Test accuracy: 0.9677419066429138\n"
     ]
    }
   ],
   "source": [
    "nn.train(X, y, range(5, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 2 reaches accuracy of 96% with just 2 nodes. We will take P=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 3\n",
    "### Optimal number of hidden layers with P/2 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['    def train_network_3(self, X, y):\\n',\n",
       "  '        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=5)\\n',\n",
       "  '        P = 6\\n',\n",
       "  '        for num_layers in range(1, 10):\\n',\n",
       "  '            nodes = [64] + [int(P / 2)] * num_layers\\n',\n",
       "  '            model = self.base_model(nodes)\\n',\n",
       "  '            summary = model.fit(X_train, y_train, epochs=10, verbose=0)\\n',\n",
       "  '            score = model.evaluate(X_test, y_test)\\n',\n",
       "  \"            print('Test loss:', score[0])\\n\",\n",
       "  \"            print('Test accuracy:', score[1])\\n\"],\n",
       " 83)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsourcelines(nn.train_network_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 5ms/step\n",
      "Test loss: 0.16075359085562882\n",
      "Test accuracy: 0.9677418956331386\n",
      "157/157 [==============================] - 1s 5ms/step\n",
      "Test loss: 0.14322554970243176\n",
      "Test accuracy: 0.9677418956331386\n",
      "157/157 [==============================] - 1s 5ms/step\n",
      "Test loss: 0.14281515644234458\n",
      "Test accuracy: 0.9677418956331386\n",
      "157/157 [==============================] - 1s 5ms/step\n",
      "Test loss: 0.1427883968991079\n",
      "Test accuracy: 0.9677418956331386\n",
      "157/157 [==============================] - 1s 5ms/step\n",
      "Test loss: 0.14293263776666798\n",
      "Test accuracy: 0.9677418956331386\n",
      "157/157 [==============================] - 1s 6ms/step\n",
      "Test loss: 0.390590252390333\n",
      "Test accuracy: 0.9677418956331386\n",
      "157/157 [==============================] - 1s 6ms/step\n",
      "Test loss: 0.39060161106146063\n",
      "Test accuracy: 0.9677418956331386\n",
      "157/157 [==============================] - 1s 6ms/step\n",
      "Test loss: 0.14275720819925805\n",
      "Test accuracy: 0.9677418956331386\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Test loss: 0.39056740160201003\n",
      "Test accuracy: 0.9677418956331386\n"
     ]
    }
   ],
   "source": [
    "nn.train_network_3(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are getting accuracy with only 2 layers. We will take hidden layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['    def train_network_4(self, X, y):\\n',\n",
       "  '        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=5)\\n',\n",
       "  '        for P in range(2, 12):\\n',\n",
       "  '            for num_layers in range(1, 5):\\n',\n",
       "  '                nodes = [64] + [int(P / 2)] * num_layers\\n',\n",
       "  '                model = self.base_model(nodes)\\n',\n",
       "  '                summary = model.fit(X_train, y_train, epochs=10, verbose=0)\\n',\n",
       "  '                score = model.evaluate(X_test, y_test)\\n',\n",
       "  \"                print('Test loss:', score[0])\\n\",\n",
       "  \"                print('Test accuracy:', score[1])\\n\",\n",
       "  \"                print('Nodes:', P)\\n\"],\n",
       " 94)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsourcelines(nn.train_network_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 11ms/step\n",
      "Test loss: 0.1598698948598971\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 2\n",
      "157/157 [==============================] - 1s 8ms/step\n",
      "Test loss: 0.39059814108405144\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 2\n",
      "157/157 [==============================] - 1s 8ms/step\n",
      "Test loss: 0.14374571450197013\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 2\n",
      "157/157 [==============================] - 2s 10ms/step\n",
      "Test loss: 0.3905639768026437\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 2\n",
      "157/157 [==============================] - 2s 13ms/step\n",
      "Test loss: 0.1599990817581772\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 3\n",
      "157/157 [==============================] - 2s 12ms/step\n",
      "Test loss: 0.18908511311005635\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 3\n",
      "157/157 [==============================] - 2s 11ms/step\n",
      "Test loss: 0.1435745235081691\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 3\n",
      "157/157 [==============================] - 2s 14ms/step\n",
      "Test loss: 0.3905894463988626\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 3\n",
      "157/157 [==============================] - 2s 12ms/step\n",
      "Test loss: 0.15686268050959157\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 4\n",
      "157/157 [==============================] - 2s 11ms/step\n",
      "Test loss: 0.39060870078718585\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 4\n",
      "157/157 [==============================] - 2s 12ms/step\n",
      "Test loss: 0.3906026197846528\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 4\n",
      "157/157 [==============================] - 2s 11ms/step\n",
      "Test loss: 0.3906031144652397\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 4\n",
      "157/157 [==============================] - 2s 11ms/step\n",
      "Test loss: 0.14637929846526712\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 5\n",
      "157/157 [==============================] - 2s 11ms/step\n",
      "Test loss: 0.14272515247961517\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 5\n",
      "157/157 [==============================] - 2s 14ms/step\n",
      "Test loss: 0.3905864593329703\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 5\n",
      "157/157 [==============================] - 2s 12ms/step\n",
      "Test loss: 0.3905813688305533\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 5\n",
      "157/157 [==============================] - 2s 14ms/step\n",
      "Test loss: 0.1459290730725428\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 6\n",
      "157/157 [==============================] - 2s 13ms/step\n",
      "Test loss: 0.14313362833041293\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 6\n",
      "157/157 [==============================] - 2s 13ms/step\n",
      "Test loss: 0.1433773672884437\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 6\n",
      "157/157 [==============================] - 2s 12ms/step\n",
      "Test loss: 0.14256884537305042\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 6\n",
      "157/157 [==============================] - 2s 14ms/step\n",
      "Test loss: 0.14699704081389556\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 7\n",
      "157/157 [==============================] - 2s 15ms/step\n",
      "Test loss: 0.14270526246660076\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 7\n",
      "157/157 [==============================] - 2s 14ms/step\n",
      "Test loss: 0.1428791457300733\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 7\n",
      "157/157 [==============================] - 2s 14ms/step\n",
      "Test loss: 0.14285955782149248\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 7\n",
      "157/157 [==============================] - 2s 14ms/step\n",
      "Test loss: 0.14346223196406274\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 8\n",
      "157/157 [==============================] - 2s 15ms/step\n",
      "Test loss: 0.14308792105905568\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 8\n",
      "157/157 [==============================] - 3s 16ms/step\n",
      "Test loss: 0.14278550303665696\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 8\n",
      "157/157 [==============================] - 2s 15ms/step\n",
      "Test loss: 0.14287474428772168\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 8\n",
      "157/157 [==============================] - 3s 18ms/step\n",
      "Test loss: 0.14453932956145826\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 9\n",
      "157/157 [==============================] - 3s 21ms/step\n",
      "Test loss: 0.14347165917894641\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 9\n",
      "157/157 [==============================] - 3s 19ms/step\n",
      "Test loss: 0.14276918113990955\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 9\n",
      "157/157 [==============================] - 3s 22ms/step\n",
      "Test loss: 0.14299120549943037\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 9\n",
      "157/157 [==============================] - 3s 19ms/step\n",
      "Test loss: 0.16121473604706443\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 10\n",
      "157/157 [==============================] - 3s 18ms/step\n",
      "Test loss: 0.14268576548357678\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 10\n",
      "157/157 [==============================] - 4s 24ms/step\n",
      "Test loss: 0.14275028390489566\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 10\n",
      "157/157 [==============================] - 4s 23ms/step\n",
      "Test loss: 0.14284230313103669\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 10\n",
      "157/157 [==============================] - 3s 21ms/step\n",
      "Test loss: 0.14295428080163944\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 11\n",
      "157/157 [==============================] - 3s 20ms/step\n",
      "Test loss: 0.1428841942814505\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 11\n",
      "157/157 [==============================] - 3s 19ms/step\n",
      "Test loss: 0.14337871199960162\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 11\n",
      "157/157 [==============================] - 3s 22ms/step\n",
      "Test loss: 0.14291843572619614\n",
      "Test accuracy: 0.9677418956331386\n",
      "Nodes: 11\n"
     ]
    }
   ],
   "source": [
    "nn.train_network_4(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 5\n",
    "### We will use same training function with each column of y as 1D matrix\n",
    "### Take average of each inidividual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['    def train_network_4(self, X, y):\\n',\n",
       "  '        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=5)\\n',\n",
       "  '        for P in range(2, 12):\\n',\n",
       "  '            for num_layers in range(1, 5):\\n',\n",
       "  '                nodes = [64] + [int(P / 2)] * num_layers\\n',\n",
       "  '                model = self.base_model(nodes)\\n',\n",
       "  '                summary = model.fit(X_train, y_train, epochs=10, verbose=0)\\n',\n",
       "  '                score = model.evaluate(X_test, y_test)\\n',\n",
       "  \"                print('Test loss:', score[0])\\n\",\n",
       "  \"                print('Test accuracy:', score[1])\\n\",\n",
       "  \"                print('Nodes:', P)\\n\"],\n",
       " 94)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsourcelines(nn.train_network_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 6s 37ms/step\n",
      "Test loss: 0.07583794576726902\n",
      "Test accuracy: 0.9872611430799885\n",
      "157/157 [==============================] - 4s 25ms/step\n",
      "Test loss: 0.17010452925779257\n",
      "Test accuracy: 0.961783436073619\n",
      "157/157 [==============================] - 3s 21ms/step\n",
      "Test loss: 0.13488652044610613\n",
      "Test accuracy: 0.9681528662420382\n",
      "157/157 [==============================] - 3s 21ms/step\n",
      "Test loss: 0.13914919108342214\n",
      "Test accuracy: 0.9745222971697521\n",
      "157/157 [==============================] - 3s 22ms/step\n",
      "Test loss: 0.09924551692737896\n",
      "Test accuracy: 0.9808917163283961\n",
      "157/157 [==============================] - 4s 26ms/step\n",
      "Test loss: 0.2000415163814642\n",
      "Test accuracy: 0.9490445833297292\n",
      "157/157 [==============================] - 4s 22ms/step\n",
      "Test loss: 0.1971288748607514\n",
      "Test accuracy: 0.9490445901633827\n",
      "157/157 [==============================] - 4s 26ms/step\n",
      "Test loss: 0.11046221425199206\n",
      "Test accuracy: 0.9745222895768038\n",
      "157/157 [==============================] - 4s 23ms/step\n",
      "Test loss: 0.09629557155974351\n",
      "Test accuracy: 0.9808917197452229\n",
      "157/157 [==============================] - 4s 23ms/step\n",
      "Test loss: 0.21777172547996423\n",
      "Test accuracy: 0.942675155818842\n",
      "157/157 [==============================] - 4s 22ms/step\n",
      "Test loss: 0.18068225691272954\n",
      "Test accuracy: 0.9554140127388535\n",
      "157/157 [==============================] - 3s 22ms/step\n",
      "Test loss: 0.1303649046428644\n",
      "Test accuracy: 0.9681528628252114\n",
      "157/157 [==============================] - 4s 24ms/step\n",
      "Test loss: 0.15864239908327724\n",
      "Test accuracy: 0.9617834436665674\n",
      "157/157 [==============================] - 4s 24ms/step\n",
      "Test loss: 0.12973486492113703\n",
      "Test accuracy: 0.9681528662420382\n",
      "157/157 [==============================] - 4s 25ms/step\n",
      "Test loss: 0.10182386674698751\n",
      "Test accuracy: 0.9808917239213445\n",
      "157/157 [==============================] - 4s 24ms/step\n",
      "Test loss: 0.05528550049301925\n",
      "Test accuracy: 0.9936305698315808\n",
      "157/157 [==============================] - 4s 24ms/step\n",
      "Test loss: 0.21975410088991662\n",
      "Test accuracy: 0.942675155818842\n",
      "157/157 [==============================] - 4s 26ms/step\n",
      "Test loss: 0.09572034065795552\n",
      "Test accuracy: 0.9808917197452229\n",
      "157/157 [==============================] - 4s 26ms/step\n",
      "Test loss: 0.13727590619663524\n",
      "Test accuracy: 0.9681528662420382\n",
      "157/157 [==============================] - 4s 25ms/step\n",
      "Test loss: 0.11868459909300136\n",
      "Test accuracy: 0.9745222929936306\n",
      "157/157 [==============================] - 4s 25ms/step\n",
      "Test loss: 0.08331460453522434\n",
      "Test accuracy: 0.9808917197452229\n",
      "157/157 [==============================] - 4s 26ms/step\n",
      "Test loss: 0.11388959937319634\n",
      "Test accuracy: 0.9745222929936306\n",
      "157/157 [==============================] - 4s 26ms/step\n",
      "Test loss: 0.1352458762325299\n",
      "Test accuracy: 0.9681528704181598\n",
      "157/157 [==============================] - 4s 27ms/step\n",
      "Test loss: 0.13964616355432827\n",
      "Test accuracy: 0.9681528662420382\n",
      "157/157 [==============================] - 4s 25ms/step\n",
      "Test loss: 0.40086820588749683\n",
      "Test accuracy: 0.9554140169149751\n",
      "157/157 [==============================] - 4s 26ms/step\n",
      "Test loss: 0.13818172479321242\n",
      "Test accuracy: 0.9745222929936306\n",
      "157/157 [==============================] - 4s 26ms/step\n",
      "Test loss: 0.08841051512463077\n",
      "Test accuracy: 0.9808917163283961\n",
      "157/157 [==============================] - 4s 26ms/step\n",
      "Test loss: 0.09731569810278097\n",
      "Test accuracy: 0.9808917163283961\n",
      "157/157 [==============================] - 4s 26ms/step\n",
      "Test loss: 0.17801986546937826\n",
      "Test accuracy: 0.9554140127388535\n",
      "157/157 [==============================] - 4s 27ms/step\n",
      "Test loss: 0.17922668728479155\n",
      "Test accuracy: 0.9554140127388535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9373330589998471"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score = nn.single_output_score(X, y)\n",
    "avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "### In this dataset, our neural network reaches accuracy of 96% with sample data and 98% with full dataset. Hence it is necessary to validate the accuracy of data with trained model.\n",
    "### Keras allows callbacks for training visualization. Function below runs for 200 epochs with 32 neurons and saves the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['    def train_with_callback(self, X, y, model_file: str = None):\\n',\n",
       "  '        if model_file is None:\\n',\n",
       "  '            model_file = self._model\\n',\n",
       "  '        plot_losses = TrainingPlot()\\n',\n",
       "  '        time_summary = TimeSummary()\\n',\n",
       "  '        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=5)\\n',\n",
       "  '        for num_nodes in range(31, 32):\\n',\n",
       "  '            nodes = [64, num_nodes]\\n',\n",
       "  '            model = self.base_model(nodes)\\n',\n",
       "  '            callbacks = [self._call_back, time_summary, plot_losses, self._call_back_model]\\n',\n",
       "  '            summary = model.fit(X_train, y_train, epochs=200, verbose=0, callbacks=callbacks)\\n',\n",
       "  '            score = model.evaluate(X_test, y_test)\\n',\n",
       "  '            plot_training_summary(summary, time_summary)\\n',\n",
       "  '            score = model.evaluate(X_test, y_test)\\n',\n",
       "  '            model.save(model_file)\\n',\n",
       "  \"            print('Test loss:', score[0])\\n\",\n",
       "  \"            print('Test accuracy:', score[1])\\n\"],\n",
       " 65)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsourcelines(nn.train_with_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-786875b5b4eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_with_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/tf/models/model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tf/notebooks/NNKeras.py\u001b[0m in \u001b[0;36mtrain_with_callback\u001b[0;34m(self, X, y, model_file)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_back\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_back_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mplot_training_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mcallback_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     callbacks.set_params({\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             self.writer = tf.summary.FileWriter(self.log_dir,\n\u001b[0;32m--> 854\u001b[0;31m                                                 self.sess.graph)\n\u001b[0m\u001b[1;32m    855\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix, session)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, event_writer, graph, graph_def)\u001b[0m\n\u001b[1;32m     89\u001b[0m       self.add_meta_graph(\n\u001b[1;32m     90\u001b[0m           meta_graph.create_meta_graph_def(graph_def=graph_def or\n\u001b[0;32m---> 91\u001b[0;31m                                            maybe_graph_as_def))\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# This set contains tags of Summary Values that have been encountered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mcreate_meta_graph_def\u001b[0;34m(meta_info_def, graph_def, saver_def, collection_list, graph, export_scope, exclude_nodes, clear_extraneous_savers, strip_default_attrs)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[0;31m# Fills in meta_info_def.stripped_op_list using the ops from graph_def.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.train_with_callback(X, y, '/tf/models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict from souce data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['    def predict(self, file_path: str, classes: [], num_lines: int = 30, model_file: str = None):\\n',\n",
       "  '        if model_file is None:\\n',\n",
       "  '            model_file = self._model\\n',\n",
       "  '        model = load_model(model_file)\\n',\n",
       "  '        with open(file_path, \"r\") as fp:\\n',\n",
       "  '            for i, line in enumerate(fp):\\n',\n",
       "  '                predict_vector = np.array(line.split(\",\")).astype(float).reshape(1, 64)\\n',\n",
       "  '                prediction = model.predict_classes(predict_vector)\\n',\n",
       "  '                print(classes[0].values[prediction])\\n',\n",
       "  '                if i > num_lines:\\n',\n",
       "  '                    break\\n'],\n",
       " 120)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsourcelines(nn.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AE002161']\n",
      "['AE002161']\n",
      "['AE002161']\n",
      "['AE002161']\n",
      "['AE005672']\n",
      "['AE002161']\n",
      "['AE002161']\n"
     ]
    }
   ],
   "source": [
    "nn.predict(\"/tf/dataset/ae002161.csv\", unique_classes, 5, \"/tf/models/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BA000004']\n",
      "['AE003852']\n",
      "['AE009442']\n",
      "['AE003852']\n",
      "['AE003853']\n",
      "['AE003852']\n",
      "['AE014075']\n"
     ]
    }
   ],
   "source": [
    "nn.predict(\"/tf/dataset/ae003852.csv\", unique_classes, 5, \"/tf/models/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "tmp = DecisionTreeClassifier(min_samples_leaf=10)\n",
    "tmp.fit(X_train, y_train)\n",
    "y_pred = tmp.predict(X_test)\n",
    "print('test', accuracy_score(y_pred, y_test))\n",
    "y_pred_train = tmp.predict(X_train)\n",
    "print('train', accuracy_score(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "# print(pca.components_)\n",
    "X_proj = pca.transform(X_test)\n",
    "\n",
    "f, ax = plt.subplots(2, sharex=True)\n",
    "f.set_figheight(10)\n",
    "ax[0].scatter(X_proj[:, 0], X_proj[:, 1], c=np.argmax(y_test, axis=1), alpha=0.9)\n",
    "ax[1].scatter(X_proj[:, 0], X_proj[:, 1], c=np.argmax(y_pred, axis=1), alpha=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
